{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.distributions import Uniform\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchaudio.transforms import Spectrogram, MelSpectrogram\n",
    "from torchaudio.transforms import TimeStretch, AmplitudeToDB, ComplexNorm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIRD_CODE = {\n",
    "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
    "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
    "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
    "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
    "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
    "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
    "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
    "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
    "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
    "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
    "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
    "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
    "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
    "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
    "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
    "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
    "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
    "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
    "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
    "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
    "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
    "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
    "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
    "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
    "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
    "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
    "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
    "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
    "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
    "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
    "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
    "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
    "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
    "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
    "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
    "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
    "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
    "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
    "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
    "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
    "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
    "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
    "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
    "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
    "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
    "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
    "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
    "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
    "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
    "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
    "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
    "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
    "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
    "}\n",
    "\n",
    "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadTrainDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 X,\n",
    "                 y,\n",
    "                 sound_dir, \n",
    "                 audio_sec=5,\n",
    "                 sample_rate=32000\n",
    "                ):\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.sound_dir = sound_dir\n",
    "        self.audio_sec = audio_sec\n",
    "        self.sample_rate = sample_rate\n",
    "        self.target_lenght = sample_rate * audio_sec\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        sound_info = (self.X[ix], self.y[ix])\n",
    "        \n",
    "        waveform = torch.load(sound_info[0])\n",
    "        input_audio_lenght = waveform.size(1)\n",
    "        target = torch.zeros([264], dtype=torch.float32)\n",
    "        target[sound_info[1]] = 1\n",
    "        \n",
    "        if input_audio_lenght > self.target_lenght:\n",
    "            dist = torch.randint(0, input_audio_lenght-self.target_lenght, (1,)).item()\n",
    "            waveform = waveform[:, dist:dist + self.target_lenght]\n",
    "        else:\n",
    "            waveform = torch.cat([waveform, torch.zeros([1, self.target_lenght - input_audio_lenght])], dim=1)\n",
    "            \n",
    "        return waveform, target, sound_info[1]        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RondomStretchMelSpectrogram(nn.Module):\n",
    "    def __init__(self, sample_rate, n_fft, top_db, max_perc):\n",
    "        super().__init__()\n",
    "        self.target_lenght = sample_rate * 5.0\n",
    "        self.time_stretch = TimeStretch(hop_length=None, n_freq=n_fft//2+1)\n",
    "        self.stft = Spectrogram(n_fft=n_fft, power=None)\n",
    "        self.com_norm = ComplexNorm(power=2.)\n",
    "        self.mel_specgram = MelSpectrogram(sample_rate, n_fft=n_fft, f_max=8000)\n",
    "        self.AtoDB= AmplitudeToDB(top_db=top_db)\n",
    "        self.dist = Uniform(1.-max_perc, 1+max_perc)\n",
    "    \n",
    "    def forward(self, x, train):\n",
    "\n",
    "        x = self.stft(x)\n",
    "        if train:\n",
    "            x = self.time_stretch(x, self.dist.sample().item())\n",
    "        x = self.com_norm(x)\n",
    "        x = self.mel_specgram.mel_scale(x)\n",
    "        x = self.AtoDB(x)\n",
    "        \n",
    "        size = torch.tensor(x.size())\n",
    "        \n",
    "        if size[3] > 157:\n",
    "            x = x[:,:,:,0:157]\n",
    "        else:\n",
    "            x = torch.cat([x, torch.cuda.FloatTensor(size[0], size[1], size[2], 157 - size[3]).fill_(0)], dim=3)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_audio(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_class=264,\n",
    "                 d_size=256,\n",
    "                 sample_rate=32000, \n",
    "                 n_fft=2**11, \n",
    "                 top_db=80):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.mel = MelSpectrogram(sample_rate, n_fft=n_fft)\n",
    "        self.norm_db = AmplitudeToDB(top_db=top_db)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(0.1)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU(0.1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=4, stride=3)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.ReLU(0.1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=4, stride=3)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        \n",
    "        self.lstm = nn.LSTM(12, 256, 2, batch_first=True)\n",
    "        self.dropout_lstm = nn.Dropout(0.3)\n",
    "        self.bn_lstm = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.output1 = nn.Linear(256, 512)\n",
    "        self.relu_out = nn.ReLU(0.1)\n",
    "        self.dropout_out = nn.Dropout(0.1)\n",
    "        self.output2 = nn.Linear(512, output_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.mel(x)\n",
    "        x = self.norm_db(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x, _ = self.lstm(x.view(x.size(0), 256, 12), None)\n",
    "        x = self.dropout_lstm(x[:, -1, :])\n",
    "        x = self.bn_lstm(x)\n",
    "        \n",
    "        x = x.view(-1, 256)\n",
    "        x = self.output1(x)\n",
    "        x = self.relu_out(x)\n",
    "        x = self.dropout_out(x)\n",
    "        \n",
    "        x = self.output2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(predict):\n",
    "    return [np.argwhere(predict[i] == predict[i].max())[0].item() for i in range(len(predict))]\n",
    "\n",
    "def get_F1_score(y_true, y_pred, average):\n",
    "    return f1_score(y_true, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, lr, betas, weight_decay, log_freq, with_cuda, model=None):\n",
    "        \n",
    "        cuda_condition = torch.cuda.is_available() and with_cuda\n",
    "        self.device = torch.device(\"cuda\" if cuda_condition else \"cpu\")\n",
    "        print(\"Use:\", \"cuda:0\" if cuda_condition else \"cpu\")\n",
    "        \n",
    "        self.model = cnn_audio().to(self.device)\n",
    "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        self.scheduler = lr_scheduler.CosineAnnealingLR(self.optim, 5)\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        if model != None:            \n",
    "            checkpoint = torch.load(model)\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            self.epoch = checkpoint['epoch']\n",
    "            self.criterion = checkpoint['loss']\n",
    "\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        print(\"Using %d GPUS for Converter\" % torch.cuda.device_count())\n",
    "        \n",
    "        self.train_data = []\n",
    "        self.test_data = []\n",
    "        \n",
    "        self.log_freq = log_freq\n",
    "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
    "        \n",
    "        self.test_loss = []\n",
    "        self.train_loss = []\n",
    "        self.train_f1_score = []\n",
    "        self.test_f1_score = []\n",
    "    \n",
    "    def train(self, epoch, X, y, batch_size=32, num_workers=5):\n",
    "        train_dataset = LoadTrainDataset(X, y, folder)\n",
    "        self.train_data = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "        self.iteration(epoch, self.train_data)\n",
    "\n",
    "    def test(self, epoch, X, y, batch_size=32, num_workers=5):\n",
    "        test_dataset = LoadTrainDataset(X, y, folder)\n",
    "        self.test_data = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "        self.iteration(epoch, self.test_data, train=False)\n",
    "\n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "        \"\"\"\n",
    "        :param epoch: 現在のepoch\n",
    "        :param data_loader: torch.utils.data.DataLoader\n",
    "        :param train: trainかtestかのbool値\n",
    "        \"\"\"\n",
    "        str_code = \"train\" if train else \"test\"\n",
    "\n",
    "        data_iter = tqdm(enumerate(data_loader), desc=\"EP_%s:%d\" % (str_code, epoch), total=len(data_loader), bar_format=\"{l_bar}{r_bar}\")\n",
    "        \n",
    "        total_element = 0\n",
    "        loss_store = 0.0\n",
    "        f1_score_store = 0.0\n",
    "        total_correct = 0\n",
    "\n",
    "        for i, data in data_iter:\n",
    "            specgram = data[0].to(self.device)\n",
    "            label = data[2].to(self.device)\n",
    "            one_hot_label = data[1].to(self.device)\n",
    "            predict_label = self.model(specgram)\n",
    "\n",
    "            # \n",
    "            predict_f1_score = get_F1_score(\n",
    "                label.cpu().detach().numpy(),\n",
    "                convert_label(predict_label.cpu().detach().numpy()),\n",
    "                average='micro'\n",
    "            )\n",
    "            \n",
    "            self.loss = self.criterion(predict_label, one_hot_label)\n",
    "\n",
    "            # \n",
    "            if train:\n",
    "                self.optim.zero_grad()\n",
    "                self.loss.backward()\n",
    "                self.optim.step()\n",
    "                self.scheduler.step()\n",
    "\n",
    "            loss_store += self.loss.item()\n",
    "            f1_score_store += predict_f1_score\n",
    "            self.avg_loss = loss_store / (i + 1)\n",
    "            self.avg_f1_score = f1_score_store / (i + 1)\n",
    "        \n",
    "            post_fix = {\n",
    "                \"epoch\": epoch,\n",
    "                \"iter\": i,\n",
    "                \"avg_loss\": round(self.avg_loss, 5),\n",
    "                \"loss\": round(loss.item(), 5),\n",
    "                \"avg_f1_score\": round(self.avg_f1_score, 5)\n",
    "            }\n",
    "\n",
    "        data_iter.write(str(post_fix))\n",
    "        self.train_loss.append(self.avg_loss) if train else self.test_loss.append(self.avg_loss)\n",
    "        self.train_f1_score.append(self.avg_f1_score) if train else self.test_f1_score.append(self.avg_f1_score)\n",
    "        \n",
    "    \n",
    "    def save(self, epoch, file_path=\"../models/2j-khold/\"):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        output_path = file_path + f\"crnn_ep{epoch}.model\"\n",
    "        torch.save(\n",
    "            {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.cpu().state_dict(),\n",
    "            'optimizer_state_dict': self.optim.state_dict(),\n",
    "            'criterion': self.criterion\n",
    "            },\n",
    "            output_path)\n",
    "        self.model.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    "    \n",
    "    def export_log(self, epoch, file_path=\"../../logs/2j-khold/\"):\n",
    "        df = pd.DataFrame({\n",
    "            \"train_loss\": self.train_loss, \n",
    "            \"test_loss\": self.test_loss, \n",
    "            \"train_F1_score\": self.train_f1_score,\n",
    "            \"test_F1_score\": self.test_f1_score\n",
    "        })\n",
    "        output_path = file_path+f\"loss.log\"\n",
    "        print(\"EP:%d logs Saved on:\" % epoch, output_path)\n",
    "        df.to_csv(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../../dataset/tensor_audio\"\n",
    "\n",
    "with open('../../dataset/train_data.pickle', 'rb') as f:\n",
    "        train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train_data])\n",
    "y = np.array([i[1] for i in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('ErrorLogging')\n",
    " \n",
    "fh = logging.FileHandler('../../logs/err_log_2jkhold.log')\n",
    "logger.addHandler(fh)\n",
    " \n",
    "sh = logging.StreamHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use: cuda:0\n",
      "Using 1 GPUS for Converter\n",
      "Total Parameters: 1440904\n",
      "StratifiedKFold(n_splits=5, random_state=2, shuffle=True)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=2, shuffle=True)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "lr = 1e-3\n",
    "weight_decay=0.00\n",
    "adam_beta1=0.5\n",
    "adam_beta2=0.99\n",
    "betas = (adam_beta1, adam_beta2)\n",
    "\n",
    "log_freq=100\n",
    "with_cuda=True\n",
    "\n",
    "model = None\n",
    "\n",
    "trainer = Trainer(lr, betas, weight_decay, log_freq, with_cuda, model)\n",
    "\n",
    "print(skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start\n",
      "TRAIN: [    0     1     2 ... 21371 21372 21373] TEST: [    4     6     9 ... 21363 21364 21370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:0: 100%|| 535/535 [00:50<00:00, 10.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 534, 'avg_loss': 0.04366, 'loss': 0.0239, 'avg_f1_score': 0.00596}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_test:0: 100%|| 134/134 [00:12<00:00, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 133, 'avg_loss': 0.02647, 'loss': 0.02291, 'avg_f1_score': 0.00466}\n",
      "TRAIN: [    0     2     4 ... 21369 21370 21372] TEST: [    1     3     5 ... 21368 21371 21373]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_train:0: 100%|| 535/535 [00:50<00:00, 10.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 534, 'avg_loss': 0.02642, 'loss': 0.02027, 'avg_f1_score': 0.00175}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_test:0: 100%|| 134/134 [00:12<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 133, 'avg_loss': 0.02764, 'loss': 0.01731, 'avg_f1_score': 0.00638}\n",
      "TRAIN: [    0     1     3 ... 21371 21372 21373] TEST: [    2    23    33 ... 21348 21358 21366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_train:0: 100%|| 535/535 [00:50<00:00, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 534, 'avg_loss': 0.02498, 'loss': 0.02373, 'avg_f1_score': 0.00012}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_test:0: 100%|| 134/134 [00:12<00:00, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 133, 'avg_loss': 0.02566, 'loss': 0.02367, 'avg_f1_score': 0.00326}\n",
      "TRAIN: [    0     1     2 ... 21371 21372 21373] TEST: [   12    18    19 ... 21359 21361 21365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_train:0: 100%|| 535/535 [00:50<00:00, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 534, 'avg_loss': 0.02477, 'loss': 0.0219, 'avg_f1_score': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_test:0: 100%|| 134/134 [00:12<00:00, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 133, 'avg_loss': 0.02821, 'loss': 0.01977, 'avg_f1_score': 0.0049}\n",
      "TRAIN: [    1     2     3 ... 21370 21371 21373] TEST: [    0    10    11 ... 21355 21369 21372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_train:0: 100%|| 535/535 [00:50<00:00, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 534, 'avg_loss': 0.02294, 'loss': 0.01949, 'avg_f1_score': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_test:0: 100%|| 134/134 [00:12<00:00, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'iter': 133, 'avg_loss': 0.02921, 'loss': 0.02152, 'avg_f1_score': 0.00443}\n",
      "TRAIN: [    0     1     2 ... 21371 21372 21373] TEST: [    4     6     9 ... 21363 21364 21370]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_train:1: 100%|| 535/535 [00:50<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'iter': 534, 'avg_loss': 0.02376, 'loss': 0.02117, 'avg_f1_score': 6e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_test:1: 100%|| 134/134 [00:12<00:00, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'iter': 133, 'avg_loss': 0.02853, 'loss': 0.01982, 'avg_f1_score': 0.00513}\n",
      "TRAIN: [    0     2     4 ... 21369 21370 21372] TEST: [    1     3     5 ... 21368 21371 21373]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EP_train:1:   7%|| 38/535 [00:04<00:52,  9.45it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e7176936fd4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-28ee7d61235d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch, X, y, batch_size, num_workers)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadTrainDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-28ee7d61235d>\u001b[0m in \u001b[0;36miteration\u001b[0;34m(self, epoch, data_loader, train)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EP_train:1:   7%|| 38/535 [00:19<00:52,  9.45it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "print(\"Training Start\")\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        trainer.train(epoch, X_train, y_train)\n",
    "        trainer.test(epoch, X_test, y_test)\n",
    "        \n",
    "    if epoch % 50 == 0 and epoch != 0:\n",
    "        trainer.save(epoch)\n",
    "        trainer.export_log(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "print(\"Training Start\")\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    trainer.train(epoch)\n",
    "    # Model Save\n",
    "    trainer.test(epoch)\n",
    "    if epoch % 50 == 0 and epoch != 0:\n",
    "        trainer.save(epoch)\n",
    "        trainer.export_log(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
